# -*- coding: utf-8 -*-
"""Tubes1_Clustering_Dika Fajar Ramadan_1301190260_IF4310

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ki2zp2gx1yBQW7TfBQwREejFz3OJwYsF

#**Tugas Besar 1 Mata Kuliah Pembelajaran Mesin**
#**Clustering**
---

###Dika Fajar Ramadan 
###1301190260 
###IF-43-10

#Import Library dan Dataset
"""

#import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
import sklearn
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.cluster import KMeans
from google.colab import files

!gdown --id 1eny4r8S2gCtyk2EVyZk0ept56aF4y6DC

#Read data
df_DataTrain = pd.read_csv('kendaraan_train.csv')

#Menampilkan 5 data teratas 
df_DataTrain.head()

"""#Eksploarsi Data 

"""

#Menampilkan bentuk matrix DataTrain 
df_DataTrain.shape

#Menampilkan informasi DataTrain
df_DataTrain.info()

#Menampilkan sebaran data 
df_DataTrain.describe()

"""#Data Preprocessing """

#Menghapus varible yang tidak digunakan
df=df_DataTrain.drop(['id','Tertarik'],axis=1)

#Menampilkan informasi 
df.info()

#Menampilkan data sebelum diubah
df

#Cek Jumlah Missing Value
df.isna().sum()

#mengisi missing value menggunakan mode (Data yang sering muncul) dan mean (rata-rata) 
df['Jenis_Kelamin']=df['Jenis_Kelamin'].fillna(df['Jenis_Kelamin'].mode().iloc[0])
df['Umur_Kendaraan']=df['Umur_Kendaraan'].fillna(df['Umur_Kendaraan'].mode().iloc[0])
df['Kendaraan_Rusak']=df['Kendaraan_Rusak'].fillna(df['Kendaraan_Rusak'].mode().iloc[0])
df.fillna(df.mean().round(), inplace=True)
df.isna().sum()

#Menampilkan data yang sudah berhasil diubah
df

#Mengubah data kategorik menjadi numerik menggunakan LabelEncoder
for col in df.columns:
  if df[col].dtypes == 'object':
    end = LabelEncoder()
    df[col]=end.fit_transform(df[col])
df.head()

#Menampilkan informasi dataset yang sudah dihandle missing value
df.info()

#Mengubah data type setiap kolom int menjadi float
for col in df.columns:
  if df[col].dtypes == 'int':
    df[col] = df[col].astype('float')
df.info()

#Menampilkan data yang sudah berhasil diubah menjadi tipe float
df

#Cek jumlah duplicate pada dataset
df.duplicated().sum()

#Menghapus data duplicate 
df.drop_duplicates(inplace=True)
df.duplicated().sum()

"""#Check Outlier"""

#plot setiap kolom pada dataset menggunakan boxplot untuk mengetahui outlier
df.plot(kind = 'box', figsize=(20,10))
plt.show()

#handling Outlier Pada Kolom Premi
q1 = df['Premi'].quantile(0.25)
q3 = df['Premi'].quantile(0.75)
iqr = q3 - q1

lower = q1 - (iqr * 1.5)
upper = q3 + (iqr * 1.5)

df['Premi'] = df['Premi'].apply(lambda x: upper if x > upper else lower if x < lower else x)
df['Premi'].plot(kind='box', figsize=(12,6) )

# Export data  
df.to_csv('kendaraan_preprocessed.csv', index=False)
files.download('kendaraan_preprocessed.csv')

"""#correlation"""

# Menampilkan korelasi antar variable
plt.figure(figsize=(15,10))
plt.title('Correlation antar variable', y=1, size=20)
sns.heatmap(df.corr(method='spearman'), annot=True, linewidths=.5, square=True, cmap=plt.cm.Blues)
plt.show()

#Menampilkan nilai korelasi antar variable 
df.corr()

#menampilkan nilai korelasi yang tinggi 
def highCorr(data, Corrmin):
  colHighCorr = set()
  for i in range (len(data.corr().columns)):
        for j in range (i) :
            if (data.corr().iloc[i, j]) > Corrmin:
                col = data.corr().columns[i]
                colHighCorr.add(col)
  return colHighCorr

#Menampilkan kolom dengan value high corelation 
colHighCorr = highCorr(df, 0.005)
colHighCorr

#Menampilkan 5 data teratas
df.head()

# Drop atribut yang mengandung data 0 atau 1
df.drop(columns=df.columns[((df == 1).mean() > 0.1)], axis=1, inplace=True)
df

"""#K-Means Clustering """

#Menghitung jarak antar centroid menggunakan Euclidean distance
def euclidean(a1, a2):
  return np.sqrt(np.sum((a1-a2)**2))

#K-Means Clustering from scratch
class k_means:
  # Inisialisasi pembentukan attribute atau variable 
  def __init__(self, k=3, iteration=100):
    self.k=k
    self.iteration=iteration
    self.centroids = []
    self.clusters = [[] for i in range(self.k)]
  
  #Pembentukan array dari data yang dimasukkan
  def value(self, X):
    self.df = X
    self.row, self.column = X.shape

    #Pembentukan centroid dengan cara random
    centroid_index = np.random.choice(self.row, self.k, replace=False)
    for i in centroid_index:
      self.centroids.append(self.df[i])

    #Melakukan looping sebanyak iterasi yang diinputkan
    #Menentukan cluster atau centroid terdekat
    for i in range(self.iteration):
      clusters = [[] for i in range(self.k)]

      #Melakukan looping sebanyak data inputan
      #Mencari centroid terdekat
      for idx, row in enumerate(self.df):
        closer_centroid = self.select_closerCentroid(row)
        clusters[closer_centroid].append(idx)

      self.clusters = clusters

      # Update centroid setelah mendapatkan closer centroid
      oldCentroid = self.centroids
      self.centroids = self.setNewCentroid()

      # Melakukan Checking apakah centroid berubah
      # Menghitung jarak antara centroid baru dengan centroid yang lama
      change = False
      for i, oldCentroid in enumerate(oldCentroid):
        dist = euclidean(oldCentroid, self.centroids[i])
        if ( dist != 0):
          change = True
      if ( change == False):
        break

    # Pembuatan label cluster  
    labels = self.setLables()
    return labels

  # Memilih Centroid terdekat
  def select_closerCentroid(self, row):
    allDist = [euclidean(row, centroid) for centroid in self.centroids]
    return np.argmin(allDist)

  # Menggenerate atau membuat centroid baru
  def setNewCentroid(self):
    centroids = np.zeros((self.k, self.column))
    for cluster_idx, cluster in enumerate(self.clusters):
      new_centroid = np.mean(self.df[cluster], axis=0)
      centroids[cluster_idx] = new_centroid
    return centroids

  #generate labels
  def setLables(self):
    labels = np.empty(self.row)
    for cluster_idx, cluster in enumerate(self.clusters):
      for row in cluster:
        labels[row] = cluster_idx
    return labels

"""#Scalling"""

#Scalling data menjadi 0 sampai 1 menggunakan metode MinMaxScaller()
scalling = MinMaxScaler()
df = pd.DataFrame(scalling.fit_transform(df))
df.columns = ['Umur', 'Kode_Daerah', 'Premi', 'Kanal_Penjualan', 'Lama_Berlangganan']
df

"""Setelah menghapus data yang mengandung 0,1 dan yang memiliki korelasi tinggi
   yaitu hanya tinggal kolom Umur, Kode_Daerah, Premi, dan Kanal_Penjualan, dan Lama_Berlangganan.
   maka akan diambil dua dari lima kolom tersebut, disini saya mengambil kolom Premi dan 
   Kanal_Penjualan"""

df_select = df[['Umur', 'Premi']]
df_select

#Plot sebaran data dari variable Umur dan Premi
plt.figure(figsize=(12,8))
plt.scatter(df_select['Umur'], df_select['Premi'], s=100)
plt.title("Persebaran Data variable Umur dan Premi", size = 20)
plt.xlabel("Umur")
plt.ylabel("Premi")

# Implementasi K-Means Clustering pada data Premi & Kanal Penjualan
kMeans = k_means(k=4, iteration=10)
cluster = kMeans.value(df_select.values)
centroid = kMeans.centroids

#Plot clustering
plt.figure(figsize=(20,10))
plt.scatter(df_select['Umur'], df_select['Premi'], c=cluster, s=100) 
plt.scatter(centroid[:,0], centroid[:, 1], c='red', marker='*', linewidths=2, s=200)
plt.xlabel('Umur')
plt.ylabel('Premi')
plt.title('Clusterisasi untuk Umur dan Premi ',y=1,size=15)
plt.show()

"""#Evaluation"""

# Evaluasi menggunakan sum of squared errors
sse = []
K = list(range(1,10))
for k in K:
    kmeans = KMeans(n_clusters = k)
    kmeans.fit(df_select)
    sse.append(kmeans.inertia_)
plt.figure(figsize=(10,5))
sns.lineplot(K, sse, marker='o', color='green')
plt.xlabel('k')
plt.ylabel('SSE')
plt.title('Elbow Method')
plt.show()

"""#Experiment"""

df_select1 = df[['Umur', 'Kode_Daerah']]
df_select1

#Plot sebaran data dari variable Umur dan Kode_Daerah
plt.figure(figsize=(12,8))
plt.scatter(df_select1['Umur'], df_select1['Kode_Daerah'], s=100)
plt.title("Persebaran Data variable Umur dan Kode Daerah", size = 20)
plt.xlabel("Umur")
plt.ylabel("Kode_Daerah")

# Implementasi K-Means Clustering pada Umur & Kode_Daerah
kMeans = k_means(k=3, iteration=10)
cluster = kMeans.value(df_select1.values)
centroid = kMeans.centroids

#Plot clusterisasi untuk kolom umur dan Kode_Daerah
plt.figure(figsize=(10,6))
plt.scatter(df_select1['Umur'], df_select1['Kode_Daerah'], c=cluster, s=100)
plt.scatter(centroid[:,0], centroid[:, 1], c='red', marker='*', linewidths=2, s=200)
plt.xlabel('Umur')
plt.ylabel('Kode_Daerah')
plt.title('Clusterisasi untuk Umur dan Kode_Daerah',y=1,size=15)
plt.show()

# Evaluasi menggunakan sum of squared errors
sse = []
K = list(range(1,10))
for k in K:
    kmeans = KMeans(n_clusters = k)
    kmeans.fit(df_select1)
    sse.append(kmeans.inertia_)
plt.figure(figsize=(10,5))
sns.lineplot(K, sse, marker='o', color='green')
plt.xlabel('k')
plt.ylabel('SSE')
plt.title('Elbow Method')
plt.show()

#Select kolom untuk ekperimen data ke 2
df_select2 = df[['Premi', 'Kanal_Penjualan']]
df_select2

#Plot sebaran data dari variable Premi dan Kanal_Penjualan
plt.figure(figsize=(12,8))
plt.scatter(df_select2['Premi'], df_select2['Kanal_Penjualan'], s=100)
plt.title("Persebaran Data variable Premi dan Kanal Penjualan", size = 20)
plt.xlabel("Premi")
plt.ylabel("Kanal_Penjualan")

#Implementasi K-Means Clustering pada data Premi & Kanal Penjualan
kMeans = k_means(k=3, iteration=10)
cluster = kMeans.value(df_select2.values)
centroid = kMeans.centroids

plt.figure(figsize=(10,6))
plt.scatter(df_select2['Premi'], df_select2['Kanal_Penjualan'], c=cluster, s=100)
plt.scatter(centroid[:,0], centroid[:, 1], c='red', marker='*', linewidths=2, s=200)
plt.xlabel('Premi')
plt.ylabel('Kanal_Penjualan')
plt.title('Clusterisasi untuk Premi dan Kanal_Penjualan',y=1,size=15)
plt.show()

# Evaluasi menggunakan sum of squared errors
sse = []
K = list(range(1,10))
for k in K:
    kmeans = KMeans(n_clusters = k)
    kmeans.fit(df_select2)
    sse.append(kmeans.inertia_)
plt.figure(figsize=(10,5))
sns.lineplot(K, sse, marker='o', color='green')
plt.xlabel('k')
plt.ylabel('SSE')
plt.title('Elbow Method')
plt.show()

"""#Kesimpulan 
Berdasarkan data yang sudah diolah dan diuji, dapat disimpulkan bahwa proses clustering akan lebih optimal jika menggunakan k=3. Hal ini dapat dilihat dari grafik Elbow Method bahwa dengan k=3 data akan lebih mudah dipahami dan SSE nya pun tidak semakin kecil. selain itu data juga dapat lebih optimal jika menggunakan kolom dengan nilai korelasi yang tinggi hal ini dapat dilihat dari plot Clusterisasi bahwa ketika menggunakan kolom korelasi yang tinggi sebaran data pun lebih rapat dan lebih dekat sehingga lebih rapi dan mudah dipahami ketika sudah di clustering. 
"""